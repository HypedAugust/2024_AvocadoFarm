{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import numpy as np\n",
    "from transformers import AutoProcessor, AutoModelForVisualQuestionAnswering\n",
    "from PIL import Image\n",
    "\n",
    "# 1. 모델과 프로세서 설정\n",
    "processor = AutoProcessor.from_pretrained(\"Salesforce/blip2-flan-t5-xl\")\n",
    "model = AutoModelForVisualQuestionAnswering.from_pretrained(\"Salesforce/blip2-flan-t5-xl\")\n",
    "\n",
    "# 2. 이미지 캡션 생성 함수\n",
    "def caption_image(input_image: np.ndarray):\n",
    "    # 2.1. 입력 이미지를 PIL 형식으로 변환\n",
    "    raw_image = Image.fromarray(input_image).convert('RGB')\n",
    "    \n",
    "    # 2.2. 모델 입력 처리\n",
    "    text = \"Describe this image in detail.\"  # 더 적합한 프롬프트로 수정\n",
    "    inputs = processor(images=raw_image, text=text, return_tensors=\"pt\")\n",
    "    \n",
    "    # 2.3. 모델로 예측 수행\n",
    "    outputs = model.generate(**inputs, max_length=50)\n",
    "\n",
    "    # 2.4. 생성된 텍스트 디코딩\n",
    "    caption = processor.decode(outputs[0], skip_special_tokens=True)\n",
    "    return caption\n",
    "\n",
    "# 3. Gradio 인터페이스 설정\n",
    "iface = gr.Interface(\n",
    "    fn=caption_image, \n",
    "    inputs=gr.Image(type=\"numpy\"),  # numpy 형식의 이미지 입력\n",
    "    outputs=\"text\",\n",
    "    title=\"Image Captioning\",\n",
    "    description=\"Generate captions for images using BLIP2 model.\"\n",
    ")\n",
    "\n",
    "# 4. 애플리케이션 실행\n",
    "if __name__ == \"__main__\":\n",
    "    iface.launch()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
