{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import google.generativeai as genai\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "generation_config = { # config :  구성 및 설정, 생성 AI 모델이 텍스트 생성 시, 사용할 설정 값을 정의한 딕셔너리 \n",
    "  \"temperature\": 0,\n",
    "  \"top_k\": 1,\n",
    "  \"max_output_tokens\": 4000,\n",
    "}\n",
    "\n",
    "\n",
    "class LLM:\n",
    "    def __init__(self, model_name) -> None: # __init__ 객체 생성시 자동으로 호출되는 생성자. # None 은 반환값이 없음을 나타내는 타입 힌트. \n",
    "        self.model_name = model_name\n",
    "        self.model = self.create_model(model_name) # 여기서 self.model = model 이 왜 아니야? \n",
    "\n",
    "    def create_model(self, model_name):\n",
    "        match model_name: # match는 model name 값에 따라 다른 동작을 수행함. \n",
    "            case \"gemini-pro-vision\":\n",
    "                genai.configure(api_key=os.environ.get(\"GOOGLE_API_KEY\")) \n",
    "                return genai.GenerativeModel(model_name)\n",
    "            case \"gemini-pro\":\n",
    "                genai.configure(api_key=os.environ.get(\"GOOGLE_API_KEY\"))\n",
    "                return genai.GenerativeModel(\n",
    "                    model_name,generation_config=generation_config)\n",
    "            case \"OpenAI\":\n",
    "                return OpenAI(api_key=os.environ.get(\"OPENAI_API_KEY\"))\n",
    "            case _: # 기본값으로 작동. 어떤 모델도 매치 하지 않으면 실행 됨. \n",
    "                print(\"Not Implemented\")\n",
    "          \n",
    "    def __call__(self, prompt, image=None): # __call__은 객체를 함수 처럼 호출하게 하는 특수 매서드임. 이미지 전달 안됐을 경우 None으로 처리리\n",
    "        if self.model_name == 'gemini-pro-vision':\n",
    "            response = self.model.generate_content(\n",
    "                [image, prompt]\n",
    "            )\n",
    "        elif self.model_name == \"gemini-pro\":\n",
    "            response = self.model.generate_content(\n",
    "                prompt)\n",
    "            return response.text\n",
    "        \n",
    "        elif self.model_name == 'OpenAI':\n",
    "            res = self.model.chat.completions.create(\n",
    "                model=\"gpt-3.5-turbo-1106\",\n",
    "                # response_format={\"type\": \"json_object\"},\n",
    "                messages=[ \n",
    "                    # {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "                    {\"role\": \"user\", \"content\": f\"{prompt}\"},\n",
    "                ],\n",
    "                # seed=10,\n",
    "                temperature=0\n",
    "            )\n",
    "            return res.choices[0].message.content "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
