{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) 이 문단에서 parameters(파라미터)란?\n",
    "파라미터는 모델이 학습하는 동안 조정되는 값\n",
    "eg) 가중치(weight)와 편향(bias)\n",
    "\n",
    "2) 손실 함수와 옵티마이저는 모델을 어떻게 학습시킬지를 설명하는 도구\n",
    "옵티마이저(optimizer)는 모델의 파라미터(가중치와 편향)를 조정하여 손실을 줄이는 역할을 함. \n",
    "\n",
    "3) 손실 함수를 통해 모델이 얼마나 틀렸는지를 측정한 후, \n",
    "옵티마이저가 이를 기반으로 모델의 가중치와 편향 같은 파라미터를 업데이트한다. \n",
    "\n",
    "4) 하이퍼 파라미터는 모델을 학습시키기 전에 사용자가 설정하는 값\n",
    "파라미터는 모델이 학습하면서 자동으로 조정되는 값인 반면, \n",
    "하이퍼 파라미터는 학습 전에 사용자가 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 1])\n",
      "tensor([[0.3982],\n",
      "        [0.4049],\n",
      "        [0.4116],\n",
      "        [0.4184],\n",
      "        [0.4251],\n",
      "        [0.4318],\n",
      "        [0.4386],\n",
      "        [0.4453],\n",
      "        [0.4520],\n",
      "        [0.4588]])\n"
     ]
    }
   ],
   "source": [
    "# Linear Regression 모델 생성 및 데이터 준비\n",
    "import torch\n",
    "from torch import nn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# create known parameters\n",
    "weight = 0.7\n",
    "bias = 0.3\n",
    "\n",
    "# create input data\n",
    "start = 0\n",
    "end = 1\n",
    "step = 0.02\n",
    "X = torch.arange(start, end, step).unsqueeze(dim=1)  # (N, 1)으로 변환\n",
    "y = weight * X + bias\n",
    "\n",
    "# 데이터 분할\n",
    "train_split = int(0.8 * len(X))\n",
    "X_train, y_train = X[:train_split], y[:train_split]\n",
    "X_test, y_test = X[train_split:], y[train_split:]\n",
    "\n",
    "# Linear Regression 모델 클래스 정의\n",
    "class LinearRegressionModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.weights = nn.Parameter(torch.randn(1, requires_grad=True, dtype=torch.float))\n",
    "        self.bias = nn.Parameter(torch.randn(1, requires_grad=True, dtype=torch.float))\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.weights * x + self.bias\n",
    "\n",
    "# 모델 생성\n",
    "model_0 = LinearRegressionModel()\n",
    "\n",
    "# 예측 전 X_test 차원 확인 및 변환 (필요할 경우)\n",
    "print(X_test.shape)  # 2차원인지 확인\n",
    "if len(X_test.shape) == 1:\n",
    "    X_test = X_test.unsqueeze(dim=1)  # 1차원일 경우 2차원으로 변환\n",
    "\n",
    "# 추론 모드로 예측 수행\n",
    "with torch.inference_mode():\n",
    "    y_preds = model_0(X_test)\n",
    "\n",
    "# 예측 결과 출력\n",
    "print(y_preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([0.3367], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0.1288], requires_grad=True)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3 Train Models \n",
    "# in \n",
    "list(model_0.parameters()) # 선형회귀 클래스에서 설정한 weight,bias가 결과로 뜬다. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('weights', tensor([0.3367])), ('bias', tensor([0.1288]))])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check out our model's parameters (a parameter is a value that the model sets itself)\n",
    "model_0.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup a loss function\n",
    "loss_fn = nn.L1Loss()\n",
    "\n",
    "# Setup an optimizer (stochastic gradient descent)\n",
    "optimizer = torch.optim.SGD(params=model_0.parameters(), # we want to optimize the parameters present in our model\n",
    "                            lr=0.01) # lr = learning rate = possibly the most important hyperparameter you can set\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a regression problem (like ours), a loss function of nn.L1Loss() and an optimizer like torch.optim.SGD() will suffice.\n",
    "\n",
    "For a classification problem like classifying whether a photo is of a dog or a cat, you'll likely want to use a loss function of nn.BCELoss() (binary cross entropy loss)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building a training loop (and a testing loop) in PyTorch\n",
    "\n",
    "Forward pass: 모델에 데이터를 넣고 예측값을 계산.\n",
    "Calculate loss: 예측값과 실제 정답을 비교해서 손실을 계산.\n",
    "Optimizer zero grad: 기울기를 0으로 초기화.\n",
    "Loss backward: 역전파를 통해 파라미터에 대한 기울기를 계산.\n",
    "Optimizer step: 기울기를 기반으로 파라미터를 업데이트해 손실을 줄이려는 과정.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "1Forward pass (this involves data moving through our model's forward() functions) to make predictions on data - also called forward propagation\n",
    "- Forward pass는 입력 데이터가 모델을 통과해 예측값을 계산하는 과정\n",
    "- 입력 데이터 → 모델의 forward() 함수 → 예측값 출력\n",
    "\n",
    "2Calculate the loss (compare forward pass predictions to ground truth labels)\n",
    "- loss : **예측값(y_hat)**을 **실제 정답(ground truth labels)**과 비교\n",
    "- Ground truth labels는 실제 정답값\n",
    "\n",
    "3Optimizer zero grad \n",
    "- Optimizer zero grad는 옵티마이저가 이전에 계산된 기울기(gradient)를 0으로 초기화하는 것\n",
    "- 기울기(gradient)를 초기화해서 이전 기울기가 다음 계산에 영향을 주지 않도록 하는 것.\n",
    "\n",
    "4Loss backward - move backwards through the network to calculate the gradients of each of the parameters of our model with respect to the loss \n",
    "- 역전파는 손실을 기반으로 모델의 각 파라미터(가중치와 편향)에 대한 기울기(gradient)를 계산하는 과정\n",
    "- 가중치와 편향을 얼마나 조정해야 하는지를 계산\n",
    "\n",
    "5Optimizer step - use the optimizer to adjust our model's parameters to try and improve the loss \n",
    "- Optimizer step은 옵티마이저(optimizer)가 모델의 파라미터(가중치와 편향)를 업데이트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0|Loss:0.31288138031959534|Test loss:0.48106518387794495\n",
      "OrderedDict([('weights', tensor([0.3406])), ('bias', tensor([0.1388]))])\n",
      "Epoch:10|Loss:0.1976713240146637|Test loss:0.3463551998138428\n",
      "OrderedDict([('weights', tensor([0.3796])), ('bias', tensor([0.2388]))])\n",
      "Epoch:20|Loss:0.08908725529909134|Test loss:0.21729660034179688\n",
      "OrderedDict([('weights', tensor([0.4184])), ('bias', tensor([0.3333]))])\n",
      "Epoch:30|Loss:0.053148526698350906|Test loss:0.14464017748832703\n",
      "OrderedDict([('weights', tensor([0.4512])), ('bias', tensor([0.3768]))])\n",
      "Epoch:40|Loss:0.04543796554207802|Test loss:0.11360953003168106\n",
      "OrderedDict([('weights', tensor([0.4748])), ('bias', tensor([0.3868]))])\n",
      "Epoch:50|Loss:0.04167863354086876|Test loss:0.09919948130846024\n",
      "OrderedDict([('weights', tensor([0.4938])), ('bias', tensor([0.3843]))])\n",
      "Epoch:60|Loss:0.03818932920694351|Test loss:0.08886633068323135\n",
      "OrderedDict([('weights', tensor([0.5116])), ('bias', tensor([0.3788]))])\n",
      "Epoch:70|Loss:0.03476089984178543|Test loss:0.0805937647819519\n",
      "OrderedDict([('weights', tensor([0.5288])), ('bias', tensor([0.3718]))])\n",
      "Epoch:80|Loss:0.03132382780313492|Test loss:0.07232122868299484\n",
      "OrderedDict([('weights', tensor([0.5459])), ('bias', tensor([0.3648]))])\n",
      "Epoch:90|Loss:0.02788739837706089|Test loss:0.06473556160926819\n",
      "OrderedDict([('weights', tensor([0.5629])), ('bias', tensor([0.3573]))])\n",
      "Epoch:100|Loss:0.024458957836031914|Test loss:0.05646304413676262\n",
      "OrderedDict([('weights', tensor([0.5800])), ('bias', tensor([0.3503]))])\n",
      "Epoch:110|Loss:0.021020207554101944|Test loss:0.04819049686193466\n",
      "OrderedDict([('weights', tensor([0.5972])), ('bias', tensor([0.3433]))])\n",
      "Epoch:120|Loss:0.01758546568453312|Test loss:0.04060482233762741\n",
      "OrderedDict([('weights', tensor([0.6141])), ('bias', tensor([0.3358]))])\n",
      "Epoch:130|Loss:0.014155393466353416|Test loss:0.03233227878808975\n",
      "OrderedDict([('weights', tensor([0.6313])), ('bias', tensor([0.3288]))])\n",
      "Epoch:140|Loss:0.010716589167714119|Test loss:0.024059748277068138\n",
      "OrderedDict([('weights', tensor([0.6485])), ('bias', tensor([0.3218]))])\n",
      "Epoch:150|Loss:0.0072835334576666355|Test loss:0.016474086791276932\n",
      "OrderedDict([('weights', tensor([0.6654])), ('bias', tensor([0.3143]))])\n",
      "Epoch:160|Loss:0.0038517764769494534|Test loss:0.008201557211577892\n",
      "OrderedDict([('weights', tensor([0.6826])), ('bias', tensor([0.3073]))])\n",
      "Epoch:170|Loss:0.008932482451200485|Test loss:0.005023092031478882\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch:180|Loss:0.008932482451200485|Test loss:0.005023092031478882\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch:190|Loss:0.008932482451200485|Test loss:0.005023092031478882\n",
      "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "# An epoch is one loop through the data... \n",
    "# (this is a hyperparameter because we've set it ourselves)\n",
    "epochs = 200 \n",
    "\n",
    "# Track different values\n",
    "epoch_count = []\n",
    "loss_values = []\n",
    "test_loss_values = []\n",
    "\n",
    "### Training\n",
    "# 0. Loop through the data\n",
    "for epoch in range(epochs):\n",
    "    # set the model to training mode \n",
    "    model_0.train() \n",
    "    # train mode in PyTorch sets all parameters \n",
    "    # that require gradients to require gradients \n",
    "    \n",
    "    # 1. Forward pass \n",
    "    y_pred = model_0(X_train)\n",
    "    \n",
    "    # 2. Calculate the loss \n",
    "    loss = loss_fn(y_pred, y_train)\n",
    "    \n",
    "    # 3. Optimizer zero grad \n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # 4. Perform backpropagation on the loss with respect to the parameters of the model\n",
    "    loss.backward()\n",
    "    \n",
    "    # 5. Step the optimizer (perform gradient descent)\n",
    "    optimizer.step()\n",
    "    \n",
    "    ### Testing \n",
    "    model_0.eval() \n",
    "    #훈련 중과는 달리 평가나 추론할 때는 기울기 계산이 \n",
    "    # 필요 없으므로 메모리 절약과 속도 향상을 위해 평가 모드를 사용\n",
    "    with torch.inference_mode(): \n",
    "        #기울기 추적을 비활성화하여 \n",
    "        # 추론 시에 메모리 사용량을 줄이고 속도를 높이는 모드\n",
    "        test_pred = model_0(X_test)\n",
    "        \n",
    "        # Do the forward pass\n",
    "        test_pred = model_0(X_test)\n",
    "        \n",
    "        # Calculate the loss \n",
    "        test_loss = loss_fn(test_pred, y_test)\n",
    "    \n",
    "    # Print out What is happenin' 이거 무슨 코드인지 해석좀 해줘\n",
    "    if epoch % 10 == 0:\n",
    "        # 에포크(epoch)가 10의 배수일 때마다 \n",
    "        # 훈련 과정의 진행 상황을 출력하고, 손실 값을 기록\n",
    "        epoch_count.append(epoch)  # 현재 에포크 저장\n",
    "        loss_values.append(loss)  # 훈련 손실 저장\n",
    "        test_loss_values.append(test_loss)  # 테스트 손실 저장\n",
    "        print(f'Epoch:{epoch}|Loss:{loss}|Test loss:{test_loss}')\n",
    "        \n",
    "        # print out model state_dict() \n",
    "        print(model_0.state_dict())  # 이거는 이제 200번까지 gd한거 나오는거지?\n",
    "    \n",
    "    \n",
    "#이 코드는 훈련 과정과 테스트 과정을 통해 모델의 성능을 평가하고, \n",
    "# 훈련 손실과 테스트 손실을 **에포크(epoch)**마다 기록하여 \n",
    "# **학습 및 평가 곡선(training and test curves)**을 \n",
    "# 그릴 수 있는 구조로 되어 있다. \n",
    "    \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.31288138, 0.19767132, 0.08908726, 0.05314853, 0.04543797,\n",
       "        0.04167863, 0.03818933, 0.0347609 , 0.03132383, 0.0278874 ,\n",
       "        0.02445896, 0.02102021, 0.01758547, 0.01415539, 0.01071659,\n",
       "        0.00728353, 0.00385178, 0.00893248, 0.00893248, 0.00893248],\n",
       "       dtype=float32),\n",
       " [tensor(0.4811),\n",
       "  tensor(0.3464),\n",
       "  tensor(0.2173),\n",
       "  tensor(0.1446),\n",
       "  tensor(0.1136),\n",
       "  tensor(0.0992),\n",
       "  tensor(0.0889),\n",
       "  tensor(0.0806),\n",
       "  tensor(0.0723),\n",
       "  tensor(0.0647),\n",
       "  tensor(0.0565),\n",
       "  tensor(0.0482),\n",
       "  tensor(0.0406),\n",
       "  tensor(0.0323),\n",
       "  tensor(0.0241),\n",
       "  tensor(0.0165),\n",
       "  tensor(0.0082),\n",
       "  tensor(0.0050),\n",
       "  tensor(0.0050),\n",
       "  tensor(0.0050)])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.array(torch.tensor(loss_values).numpy()), test_loss_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model to: models\\01_pytorch_workflow_model_0.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'ls'��(��) ���� �Ǵ� �ܺ� ����, ������ �� �ִ� ���α׷�, �Ǵ�\n",
      "��ġ ������ �ƴմϴ�.\n"
     ]
    }
   ],
   "source": [
    "# Saving a model in Pytorch \n",
    "# torch.save(), torch.load(), torch.nn.Module.load_state_dict()\n",
    "\n",
    "# Saving our Pytoch model \n",
    "from pathlib import Path \n",
    "\n",
    "# 1. Create models directory \n",
    "MODEL_PATH = Path(\"models\")\n",
    "MODEL_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# 2. Create model save path\n",
    "MODEL_NAME = \"01_pytorch_workflow_model_0.pth\"\n",
    "MODEL_SAVE_PATH = MODEL_PATH / MODEL_NAME\n",
    "\n",
    "# 3. Save the model state dict\n",
    "print(f\"Saving model to: {MODEL_SAVE_PATH}\")\n",
    "torch.save(obj=model_0.state_dict(),\n",
    "           f=MODEL_SAVE_PATH)\n",
    "\n",
    "!ls -l models \n",
    "# 폴더 안의 파일 목록과 \n",
    "#파일 정보를 나열하여 모델이 \n",
    "# 제대로 저장되었는지 확인하는 명령어"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading a PyTorch model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.1+cpu'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 6. putting it all together  \n",
    "# import Pytorch and matplolib\n",
    "import torch \n",
    "from torch import nn \n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "# check pytorch version \n",
    "torch.__version__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "# Setup device agnostic code\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.1 Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.2 Building a PyTorch Linear model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.3 Training \n",
    "# Loss function\n",
    "# Optimizer\n",
    "# Training loop\n",
    "# Testing loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.4 Making and evaluating predictions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.5 Saving and Loading a trained model "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-new-94B1aYL8-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
